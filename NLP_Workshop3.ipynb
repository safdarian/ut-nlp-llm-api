{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CQygw2dda_0Y",
        "7tn42dLKDTmC",
        "Nxia_gM7-iqu",
        "necLU8aKTPcF",
        "wZkAc-SRrTkR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "CQygw2dda_0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "7tn42dLKDTmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install together"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "YFajhEUyDNqs",
        "outputId": "eb0a1550-6020-45ae-a5f6-515e865e8d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting together\n",
            "  Downloading together-1.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.11.10)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from together)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (17.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.10.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.15.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.16,>=0.9->together) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Downloading together-1.3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, together\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "Successfully installed pillow-10.4.0 together-1.3.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "508d2cf0e89f44beadce94e69a6fa83a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Setup"
      ],
      "metadata": {
        "id": "Nxia_gM7-iqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "with open('config.json', 'r') as file:\n",
        "    config = json.load(file)\n",
        "    togetherAI_api_key = config[\"togetherAI_api_key\"]\n",
        "    OPEN_AI_API_KEY = config[\"OpenAI_api_key\"]\n",
        "    weather_api_key = config[\"weather\"]\n",
        "    XAI_API_KEY = config[\"grok\"]\n",
        "\n",
        "os.environ['TOGETHER_API_KEY'] = togetherAI_api_key"
      ],
      "metadata": {
        "id": "CEZywzr0-km-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "# together.ai API Using OpenAI client\n",
        "client_together = OpenAI(\n",
        "  api_key=os.environ[\"TOGETHER_API_KEY\"],\n",
        "  base_url=\"https://api.together.xyz/v1\"\n",
        ")\n",
        "\n",
        "# together.ai API Using together.ai client\n",
        "# from together import Together\n",
        "# client_together = Together()\n",
        "\n",
        "# OpenAI API Using OpenAI client\n",
        "from openai import OpenAI\n",
        "client_openai = OpenAI(\n",
        "  api_key=OPEN_AI_API_KEY\n",
        ")\n",
        "\n",
        "# grok\n",
        "# client_grok = OpenAI(\n",
        "#   api_key=XAI_API_KEY,\n",
        "#   base_url=\"https://api.x.ai/v1\",\n",
        "# )\n"
      ],
      "metadata": {
        "id": "VtNaxfdvAqum"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yS7kDiN1_mmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQL Database"
      ],
      "metadata": {
        "id": "necLU8aKTPcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sql_schema = \"\"\"CREATE TABLE WeatherData (\n",
        "    Region VARCHAR(255),\n",
        "    Country VARCHAR(255),\n",
        "    State VARCHAR(255),\n",
        "    City VARCHAR(255),\n",
        "    Month INT,\n",
        "    Day INT,\n",
        "    Year INT,\n",
        "    Temperature FLOAT\n",
        ");\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JfMaZzIuTYAf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iQGHj1IVcmn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Approaches"
      ],
      "metadata": {
        "id": "ykgVALOGay0x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before Structured Output"
      ],
      "metadata": {
        "id": "07wS1gxCAJ5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"give me country names list with average temperature less than 30\"\n",
        "\n",
        "extract = client_together.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"The following is a question about this SQL database: {sql_schema}. generate a sql query to answer users question.\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": question,\n",
        "        },\n",
        "    ],\n",
        "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "result = extract\n",
        "print(result.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfp1cixtAOhs",
        "outputId": "0b3b1e84-8966-4a17-f592-55d10229718e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To get the list of country names with an average temperature less than 30, you can use the following SQL query:\n",
            "\n",
            "```sql\n",
            "SELECT Country\n",
            "FROM WeatherData\n",
            "GROUP BY Country\n",
            "HAVING AVG(Temperature) < 30;\n",
            "```\n",
            "\n",
            "This query works as follows:\n",
            "\n",
            "- `GROUP BY Country` groups the rows by country, allowing us to calculate aggregate values for each country.\n",
            "- `HAVING AVG(Temperature) < 30` filters these groups to only include countries where the average temperature is less than 30.\n",
            "\n",
            "Note that this query assumes that there are temperature readings for each country. If a country has no temperature readings, it will not be included in the results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.usage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xK4X-I8Az8H",
        "outputId": "908e8a58-1068-4215-c8f9-1a732ff44e58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CompletionUsage(completion_tokens=139, prompt_tokens=113, total_tokens=252, completion_tokens_details=None, prompt_tokens_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Prompt"
      ],
      "metadata": {
        "id": "0pi-RiR_8pLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def simple_prompt(question):\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. generate a sql query to answer users question.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ],\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": TextToSQLResult.model_json_schema(),\n",
        "        },\n",
        "        temperature=0,\n",
        "\n",
        "    )\n",
        "    # print(extract.choices[0].message.model_dump())\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "question = \"give me country names list with average temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than 30\"\n",
        "\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = simple_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3izgGKi8ocG",
        "outputId": "9b632d21-fbe0-4742-ed5e-5426abf93995"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"generated_query\": \"SELECT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few Shot"
      ],
      "metadata": {
        "id": "azBMo0Da8yjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "few_shot_system_prompt = \"\"\"\n",
        "The following is a question about this SQL database: {}.\n",
        "generate a sql query to answer users question.\n",
        "\n",
        "When answering user question follow these examples:\n",
        "Question: give me country names list with temperature less than 30?\n",
        "Answer: SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30.\n",
        "Question: give me country names list with average temperature less than 30?\n",
        "Answer: SELECT Country FROM WeatherData GROUP BY Country HAVING AVG(Temperature) < 30.\n",
        "\"\"\"\n",
        "\n",
        "def few_shot_prompt(question):\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": few_shot_system_prompt.format(sql_schema),\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ],\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": TextToSQLResult.model_json_schema(),\n",
        "        },\n",
        "        temperature=0,\n",
        "\n",
        "    )\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than 20\"\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = few_shot_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAqh2auA8yjg",
        "outputId": "c9dd39ec-0b90-463b-f91d-a487ccad0b9c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"generated_query\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 20\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoT"
      ],
      "metadata": {
        "id": "1r1sTOEF8y7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cot create"
      ],
      "metadata": {
        "id": "lqlUtkmCo0NH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Step(BaseModel):\n",
        "    explanation: str\n",
        "    current_question: str = Field(\"rewrote question\")\n",
        "\n",
        "class TextToSQLReasoning(BaseModel):\n",
        "    steps: List[Step] = Field(description=\"Reasoning Steps to get to final SQL Query\")\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def CoT_prompt(question):\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. generate a sql query to answer users question. make your output step by step\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ],\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": TextToSQLReasoning.model_json_schema(),\n",
        "        },\n",
        "        temperature=0,\n",
        "\n",
        "    )\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than 30\"\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = CoT_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiV5ChKL8y7g",
        "outputId": "bc145157-b8e8-453b-f50f-a11693e16f9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"steps\": [\n",
            "    {\n",
            "      \"explanation\": \"To get the list of country names with a temperature less than 30, we need to select the `Country` column from the `WeatherData` table.\",\n",
            "      \"current_question\": \"SELECT Country FROM WeatherData\"\n",
            "    },\n",
            "    {\n",
            "      \"explanation\": \"Next, we need to add a condition to filter the results to only include rows where the temperature is less than 30. We can do this using the `WHERE` clause.\",\n",
            "      \"current_question\": \"SELECT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "    },\n",
            "    {\n",
            "      \"explanation\": \"Finally, to get a list of unique country names, we can use the `DISTINCT` keyword.\",\n",
            "      \"current_question\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "    }\n",
            "  ],\n",
            "  \"generated_query\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoT parse"
      ],
      "metadata": {
        "id": "lvCtOMbao4KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# client_together.beta.chat.completions.parse??"
      ],
      "metadata": {
        "id": "nhVkGhVppf8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Step(BaseModel):\n",
        "    explanation: str\n",
        "    current_question: str = Field(\"rewrote question\")\n",
        "\n",
        "class TextToSQLReasoning(BaseModel):\n",
        "    steps: List[Step] = Field(description=\"Reasoning Steps to get to final SQL Query\")\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def CoT_prompt(question):\n",
        "    extract = client_together.beta.chat.completions.parse(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. generate a sql query to answer users question. make your output step by step\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ],\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": TextToSQLReasoning.model_json_schema(),\n",
        "        },\n",
        "        temperature=0,\n",
        "\n",
        "    )\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than 30\"\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = CoT_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ItAFDvjoYl-",
        "outputId": "38b5aef6-afee-4420-cd44-3c01d23a0bc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"steps\": [\n",
            "    {\n",
            "      \"explanation\": \"To get the list of country names with a temperature less than 30, we need to select the `Country` column from the `WeatherData` table.\",\n",
            "      \"current_question\": \"SELECT Country FROM WeatherData\"\n",
            "    },\n",
            "    {\n",
            "      \"explanation\": \"Next, we need to add a condition to filter the results to only include rows where the temperature is less than 30. We can do this using the `WHERE` clause.\",\n",
            "      \"current_question\": \"SELECT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "    },\n",
            "    {\n",
            "      \"explanation\": \"Finally, to get a list of unique country names, we can use the `DISTINCT` keyword.\",\n",
            "      \"current_question\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "    }\n",
            "  ],\n",
            "  \"generated_query\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Critique Agent"
      ],
      "metadata": {
        "id": "MA4RclGM80AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "import time\n",
        "\n",
        "# class Step(BaseModel):\n",
        "#     explanation: str\n",
        "#     current_question: str = Field(\"rewrote question\")\n",
        "\n",
        "# class TextToSQLReasoning(BaseModel):\n",
        "#     steps: List[Step] = Field(description=\"Reasoning Steps to get to final SQL Query\")\n",
        "#     generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "class Critique(BaseModel):\n",
        "    feedback: str = Field(description=\"Feedback about the generated query.\")\n",
        "    is_ok: Literal[True, False] = Field(description=\"Does the query exactly generate the desired output and has nothing to fix?\")\n",
        "\n",
        "def inference(messages, schema_class):\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": schema_class.model_json_schema(),\n",
        "        },\n",
        "        temperature=0,\n",
        "    )\n",
        "    return extract\n",
        "\n",
        "def critique_prompt(question):\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. generate a sql query to answer users question.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ]\n",
        "    extract = inference(messages, TextToSQLResult)\n",
        "\n",
        "    initial_query_message = extract.choices[0].message\n",
        "\n",
        "    critique_system_prompt = {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a critical thinker and Professional SQL Expert. Give feedback about the generated sql query for the user question. if you find something that should be changed also set is_ok to false\",\n",
        "            }\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": initial_query_message.content})\n",
        "    messages.append(critique_system_prompt)\n",
        "\n",
        "    extract = inference(messages, Critique)\n",
        "    feedback_query_message = extract.choices[0].message\n",
        "\n",
        "    query_rewrite_system_prompt = {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"You are a humble and professional SQL query expert. according to the question and last generated query and the professional feedback rewrite the query\",\n",
        "            }\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": feedback_query_message.content})\n",
        "    messages.append(query_rewrite_system_prompt)\n",
        "\n",
        "\n",
        "    print(\"\\n\".join([str(i) for i in messages]))\n",
        "\n",
        "    extract = inference(messages, TextToSQLResult)\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than 30\"\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = critique_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpfKvfKe80AR",
        "outputId": "4744fa00-aa7e-47d0-b020-dc10ca04cb40"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'system', 'content': 'The following is a question about this SQL database: CREATE TABLE WeatherData (\\n    Region VARCHAR(255),\\n    Country VARCHAR(255),\\n    State VARCHAR(255),\\n    City VARCHAR(255),\\n    Month INT,\\n    Day INT,\\n    Year INT,\\n    Temperature FLOAT\\n);\\n. generate a sql query to answer users question.'}\n",
            "{'role': 'user', 'content': 'give me country names list with temperature less than 30'}\n",
            "{'role': 'assistant', 'content': '{ \"generated_query\": \"SELECT Country FROM WeatherData WHERE Temperature < 30\" }'}\n",
            "{'role': 'system', 'content': 'You are a critical thinker and Professional SQL Expert. Give feedback about the generated sql query for the user question. if you find something that should be changed also set is_ok to false'}\n",
            "{'role': 'assistant', 'content': '{ \"feedback\": \"The generated query is mostly correct, but it may return duplicate country names if there are multiple records for the same country with a temperature less than 30. To get a list of unique country names, it would be better to use the DISTINCT keyword.\", \"is_ok\": false }'}\n",
            "{'role': 'user', 'content': 'You are a humble and professional SQL query expert. according to the question and last generated query and the professional feedback rewrite the query'}\n",
            "{\n",
            "  \"generated_query\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 30\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weather API Tool Use"
      ],
      "metadata": {
        "id": "yWWDaU41-cUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def get_weather(city_name):\n",
        "    api_key = weather_api_key  # Replace with your OpenWeatherMap API key\n",
        "    api_url = f'http://api.openweathermap.org/data/2.5/weather?q={city_name}&appid={api_key}&units=metric'\n",
        "\n",
        "    try:\n",
        "        response = requests.get(api_url)\n",
        "        response.raise_for_status()\n",
        "        weather_data = response.json()\n",
        "        # weather = {\n",
        "        #     'temperature': weather_data['main']['temp'],\n",
        "        #     'description': weather_data['weather'][0]['description'],\n",
        "        #     'humidity': weather_data['main']['humidity'],\n",
        "        #     'wind_speed': weather_data['wind']['speed']\n",
        "        # }\n",
        "        weather = {\n",
        "            'city_name': city_name,\n",
        "            'temperature': weather_data['main']['temp']\n",
        "        }\n",
        "        return weather\n",
        "    except requests.exceptions.HTTPError as http_err:\n",
        "        print(f'HTTP error occurred: {http_err}')\n",
        "    except Exception as err:\n",
        "        print(f'Other error occurred: {err}')\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "weather = get_weather('tehran')\n",
        "if weather:\n",
        "    print(weather)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94RJPb62MfIY",
        "outputId": "1fa88653-2a11-49ad-820d-c81a196f0bfa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'city_name': 'tehran', 'temperature': 7.62}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class get_weather_class(BaseModel):\n",
        "    city_name: str"
      ],
      "metadata": {
        "id": "-pIjTNCQQREq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TogetherAI Llama Response Format + Tool Use At the same time ❌"
      ],
      "metadata": {
        "id": "u2u-oCD5pUc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_tool_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbAgxLlC6-yE",
        "outputId": "f017be1f-f9de-4e3c-b6b9-427610fd3424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'function',\n",
              " 'function': {'name': 'get_weather_class',\n",
              "  'strict': True,\n",
              "  'parameters': {'properties': {'city_name': {'title': 'City Name',\n",
              "     'type': 'string'}},\n",
              "   'required': ['city_name'],\n",
              "   'title': 'get_weather_class',\n",
              "   'type': 'object',\n",
              "   'additionalProperties': False}}}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_tool_json = pydantic_function_tool(get_weather_class)\n",
        "\n",
        "\n",
        "tools = [\n",
        "  {'type': 'function',\n",
        " 'function': {'name': 'get_weather_class',\n",
        "  'strict': True,\n",
        "  'parameters': {'properties': {'city_name': {'title': 'City Name',\n",
        "     'type': 'string'}},\n",
        "   'required': ['city_name'],\n",
        "   'title': 'get_weather_class',\n",
        "   'type': 'object',\n",
        "   'additionalProperties': False}}}\n",
        "]\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "import time\n",
        "\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "def tool_use_prompt(question):\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. if there is no need to live weather data generate a sql query to answer users question. otherwise suggest using live weather api.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    extract = client_together.beta.chat.completions.parse(\n",
        "        messages=messages,\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format=TextToSQLResult,\n",
        "        tools=tools\n",
        "    )\n",
        "\n",
        "    print(extract.choices[0].message)\n",
        "\n",
        "    if extract.choices[0].message.tool_calls:\n",
        "        messages.append(extract.choices[0].message)\n",
        "        tool_call = extract.choices[0].message.tool_calls[0]\n",
        "        # print(tool_call)\n",
        "        # print(tool_call.function)\n",
        "        # print(tool_call.function.name)\n",
        "        # print(tool_call.function.arguments)\n",
        "        functions = {\"get_weather\": get_weather}\n",
        "        right_function = functions[tool_call.function.name]\n",
        "        tool_result = right_function(**json.loads(tool_call.function.arguments))\n",
        "        print(\"Tool Use\")\n",
        "        print(tool_result)\n",
        "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": f\"{tool_result['city_name']}'s Temperature is {tool_result['temperature']}\"})\n",
        "        print(\"\\n\".join([str(message) for message in messages]))\n",
        "\n",
        "        extract = client_together.beta.chat.completions.parse(\n",
        "            messages=messages,\n",
        "            model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "            response_format=TextToSQLResult,\n",
        "            temperature=0\n",
        "        )\n",
        "    else:\n",
        "        print(\"No Tool Use\")\n",
        "\n",
        "\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "# question = \"how is the weather in tehran right now?\"\n",
        "# question = \"give me country names list with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than tehran's current temperature\"\n",
        "\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = tool_use_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))\n",
        "print(\"-\" * 50)\n",
        "print(output[\"generated_query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "15f1ecb9-2446-4166-b806-d7193b803cb8",
        "id": "LZlf4lgXpUc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "Error code: 500 - {'error': {'message': 'Internal server error', 'type': 'server_error', 'param': None, 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-231-fcbec00ebb4d>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# question = \"Write a query to calculate the average temperature in Algiers for January over all available years.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_use_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-231-fcbec00ebb4d>\u001b[0m in \u001b[0;36mtool_use_prompt\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     35\u001b[0m         ]\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     extract = client_together.beta.chat.completions.parse(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/beta/chat/completions.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mInternalServerError\u001b[0m: Error code: 500 - {'error': {'message': 'Internal server error', 'type': 'server_error', 'param': None, 'code': None}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbAS_Ki3udwO",
        "outputId": "05dbf4ed-9cec-4b68-f9c5-47c45ff97f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'generated_query': {'description': 'Generated SQL Query for the question.',\n",
              "   'title': 'Generated Query',\n",
              "   'type': 'string'}},\n",
              " 'required': ['generated_query'],\n",
              " 'title': 'TextToSQLResult',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPb98RMQvGph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI ✅"
      ],
      "metadata": {
        "id": "jb6L_UMpYJuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "  {\n",
        "      \"type\": \"function\",\n",
        "      \"function\": {\n",
        "          \"name\": \"get_weather\",\n",
        "          \"strict\": True,\n",
        "          \"parameters\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                  \"city_name\": {\"type\": \"string\"}\n",
        "              },\n",
        "            \"required\": [\"city_name\"],\n",
        "            \"additionalProperties\": False\n",
        "          }\n",
        "      }\n",
        "  }\n",
        "]\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "import time\n",
        "\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "def tool_use_prompt(question):\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. if there is no need to live weather data generate a sql query to answer users question. otherwise suggest using live weather api.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    extract = client_openai.beta.chat.completions.parse(\n",
        "        messages=messages,\n",
        "        model=\"gpt-4o-mini\",\n",
        "        response_format=TextToSQLResult,\n",
        "        temperature=0,\n",
        "        tools=tools\n",
        "    )\n",
        "\n",
        "    print(extract.choices[0].message)\n",
        "\n",
        "    if extract.choices[0].message.tool_calls:\n",
        "        messages.append(extract.choices[0].message)\n",
        "        tool_call = extract.choices[0].message.tool_calls[0]\n",
        "        # print(tool_call)\n",
        "        # print(tool_call.function)\n",
        "        # print(tool_call.function.name)\n",
        "        # print(tool_call.function.arguments)\n",
        "        functions = {\"get_weather\": get_weather}\n",
        "        right_function = functions[tool_call.function.name]\n",
        "        tool_result = right_function(**json.loads(tool_call.function.arguments))\n",
        "        print(\"Tool Use\")\n",
        "        print(tool_result)\n",
        "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": f\"{tool_result['city_name']}'s Temperature is {tool_result['temperature']}\"})\n",
        "        print(\"\\n\".join([str(message) for message in messages]))\n",
        "        extract = client_openai.beta.chat.completions.parse(\n",
        "            messages=messages,\n",
        "            model=\"gpt-4o-mini\",\n",
        "            response_format=TextToSQLResult,\n",
        "            temperature=0\n",
        "        )\n",
        "    else:\n",
        "        print(\"No Tool Use\")\n",
        "\n",
        "\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "# question = \"how is the weather in tehran right now?\"\n",
        "# question = \"give me country names list with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than tehran's current temperature\"\n",
        "\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = tool_use_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))\n",
        "print(\"-\" * 50)\n",
        "print(output[\"generated_query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XrNADkqQCb9",
        "outputId": "d61c1503-19ef-4324-8c70-571e262a8c19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ParsedChatCompletionMessage[TextToSQLResult](content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ParsedFunctionToolCall(id='call_TNEhZlgkCrU1ncwDuk2zMvgd', function=ParsedFunction(arguments='{\"city_name\":\"Tehran\"}', name='get_weather', parsed_arguments={'city_name': 'Tehran'}), type='function')], parsed=None)\n",
            "Tool Use\n",
            "{'city_name': 'Tehran', 'temperature': 7.62}\n",
            "{'role': 'system', 'content': 'The following is a question about this SQL database: CREATE TABLE WeatherData (\\n    Region VARCHAR(255),\\n    Country VARCHAR(255),\\n    State VARCHAR(255),\\n    City VARCHAR(255),\\n    Month INT,\\n    Day INT,\\n    Year INT,\\n    Temperature FLOAT\\n);\\n. if there is no need to live weather data generate a sql query to answer users question. otherwise suggest using live weather api.'}\n",
            "{'role': 'user', 'content': \"give me country names list with temperature less than tehran's current temperature\"}\n",
            "ParsedChatCompletionMessage[TextToSQLResult](content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ParsedFunctionToolCall(id='call_TNEhZlgkCrU1ncwDuk2zMvgd', function=ParsedFunction(arguments='{\"city_name\":\"Tehran\"}', name='get_weather', parsed_arguments={'city_name': 'Tehran'}), type='function')], parsed=None)\n",
            "{'role': 'tool', 'tool_call_id': 'call_TNEhZlgkCrU1ncwDuk2zMvgd', 'content': \"Tehran's Temperature is 7.62\"}\n",
            "{\n",
            "  \"generated_query\": \"SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 7.62;\"\n",
            "}\n",
            "--------------------------------------------------\n",
            "SELECT DISTINCT Country FROM WeatherData WHERE Temperature < 7.62;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TogetherAI Tool Use As Response Format ✅"
      ],
      "metadata": {
        "id": "wZkAc-SRrTkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import pydantic_function_tool"
      ],
      "metadata": {
        "id": "4GdYzF7DvkQE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TextToSQLResult.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwY5Nhzb0MRO",
        "outputId": "490acde1-73ec-41f2-92c7-e849826e5a7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'properties': {'generated_query': {'description': 'Generated SQL Query for the question.',\n",
              "   'title': 'Generated Query',\n",
              "   'type': 'string'}},\n",
              " 'required': ['generated_query'],\n",
              " 'title': 'TextToSQLResult',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_weather_tool_json = pydantic_function_tool(get_weather_class)\n",
        "get_weather_tool_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOsQPbt01VEz",
        "outputId": "5a28c0df-49c9-4b5d-ea6a-0401aae16901"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'function',\n",
              " 'function': {'name': 'get_weather_class',\n",
              "  'strict': True,\n",
              "  'parameters': {'properties': {'city_name': {'title': 'City Name',\n",
              "     'type': 'string'}},\n",
              "   'required': ['city_name'],\n",
              "   'title': 'get_weather_class',\n",
              "   'type': 'object',\n",
              "   'additionalProperties': False}}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {\n",
        "#       \"type\": \"function\",\n",
        "#       \"function\": {\n",
        "#           \"name\": \"get_weather\",\n",
        "#           \"strict\": True,\n",
        "#           \"parameters\": {\n",
        "#               \"type\": \"object\",\n",
        "#               \"properties\": {\n",
        "#                   \"city_name\": {\"type\": \"string\"}\n",
        "#               },\n",
        "#             \"required\": [\"city_name\"],\n",
        "#             \"additionalProperties\": False\n",
        "#           },\n",
        "#       },\n",
        "#   },"
      ],
      "metadata": {
        "id": "ECGQfEDl2zJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_sql_result_json = pydantic_function_tool(TextToSQLResult)\n",
        "text_to_sql_result_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmb4xrtW1aQH",
        "outputId": "b68f94ee-8af1-48f6-b2dc-cdbd5bd2f866"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'function',\n",
              " 'function': {'name': 'TextToSQLResult',\n",
              "  'strict': True,\n",
              "  'parameters': {'properties': {'generated_query': {'description': 'Generated SQL Query for the question.',\n",
              "     'title': 'Generated Query',\n",
              "     'type': 'string'}},\n",
              "   'required': ['generated_query'],\n",
              "   'title': 'TextToSQLResult',\n",
              "   'type': 'object',\n",
              "   'additionalProperties': False}}}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "import time\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "tools = [\n",
        "    get_weather_tool_json,\n",
        "    text_to_sql_result_json\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def tool_use_prompt(question):\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. if we need live weather data for generating the query suggest using weather api.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        temperature=0,\n",
        "        tools=tools\n",
        "    )\n",
        "    print(extract.choices[0].message)\n",
        "\n",
        "    if extract.choices[0].message.tool_calls:\n",
        "        tool_call = extract.choices[0].message.tool_calls[0]\n",
        "        if tool_call.function.name == \"TextToSQLResult\":\n",
        "            print(\"Direct Output\")\n",
        "            print(tool_call)\n",
        "            output = json.loads(tool_call.function.arguments)\n",
        "        elif tool_call.function.name == \"get_weather_class\":\n",
        "            messages.append(extract.choices[0].message)\n",
        "\n",
        "            functions = {\"get_weather_class\": get_weather}\n",
        "            right_function = functions[tool_call.function.name]\n",
        "            tool_result = right_function(**json.loads(tool_call.function.arguments))\n",
        "            print(\"Tool Use\")\n",
        "            # print(tool_result)\n",
        "            messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": f\"{tool_result['city_name']}'s Temperature is {tool_result['temperature']}\"})\n",
        "            print(\"\\n\".join([str(message) for message in messages]))\n",
        "            extract = client_together.chat.completions.create(\n",
        "                messages=messages,\n",
        "                model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "                response_format={\"type\":\"json_object\" , \"schema\": TextToSQLResult.model_json_schema()},\n",
        "                temperature=0\n",
        "            )\n",
        "            output = extract.choices[0].message.content\n",
        "    else:\n",
        "        print(\"Something Went Wrong\")\n",
        "\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "# question = \"how is the weather in tehran right now?\"\n",
        "# question = \"give me country names list with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than tehran's current temperature\"\n",
        "\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = tool_use_prompt(question)\n",
        "print(\"-\" * 25)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))\n",
        "# print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86204df3-149b-48be-b004-b7d4b0469111",
        "id": "VyaDT-OdrTkV"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hojdw0xh0rmgcsp9pcedws8b', function=Function(arguments='{\"city_name\":\"Tehran\"}', name='get_weather_class'), type='function', index=0)])\n",
            "Tool Use\n",
            "{'role': 'system', 'content': 'The following is a question about this SQL database: CREATE TABLE WeatherData (\\n    Region VARCHAR(255),\\n    Country VARCHAR(255),\\n    State VARCHAR(255),\\n    City VARCHAR(255),\\n    Month INT,\\n    Day INT,\\n    Year INT,\\n    Temperature FLOAT\\n);\\n. if we need live weather data for generating the query suggest using weather api.'}\n",
            "{'role': 'user', 'content': \"give me country names list with temperature less than tehran's current temperature\"}\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hojdw0xh0rmgcsp9pcedws8b', function=Function(arguments='{\"city_name\":\"Tehran\"}', name='get_weather_class'), type='function', index=0)])\n",
            "{'role': 'tool', 'tool_call_id': 'call_hojdw0xh0rmgcsp9pcedws8b', 'content': \"Tehran's Temperature is 7.62\"}\n",
            "-------------------------\n",
            "\"{\\\"generated_query\\\": \\\"SELECT Country FROM WeatherData WHERE Temperature < 7.62\\\"}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TogetherAI Two LLM Calls ✅"
      ],
      "metadata": {
        "id": "1ojfI9ACn8Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUpDO1OEBSu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Literal\n",
        "import time\n",
        "\n",
        "tools = [\n",
        "  get_weather_tool_json\n",
        "]\n",
        "\n",
        "\n",
        "class TextToSQLResult(BaseModel):\n",
        "    generated_query: str = Field(description=\"Generated SQL Query for the question.\")\n",
        "\n",
        "\n",
        "def tool_use_prompt(question):\n",
        "    messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": f\"The following is a question about this SQL database: {sql_schema}. if there is no need to live weather data generate a sql query to answer users question. otherwise suggest using live weather api.\",\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            },\n",
        "        ]\n",
        "\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        # response_format={\n",
        "        #     \"type\": \"json_object\",\n",
        "        #     \"schema\": TextToSQLResult.model_json_schema(),\n",
        "        # },\n",
        "        temperature=0,\n",
        "        tools=tools\n",
        "    )\n",
        "    print(extract.choices[0].message)\n",
        "\n",
        "    if extract.choices[0].message.tool_calls:\n",
        "        messages.append(extract.choices[0].message)\n",
        "        tool_call = extract.choices[0].message.tool_calls[0]\n",
        "        # print(tool_call)\n",
        "        # print(tool_call.function)\n",
        "        # print(tool_call.function.name)\n",
        "        # print(tool_call.function.arguments)\n",
        "        functions = {\"get_weather_class\": get_weather}\n",
        "        right_function = functions[tool_call.function.name]\n",
        "        tool_result = right_function(**json.loads(tool_call.function.arguments))\n",
        "        print(\"Tool Use\")\n",
        "        print(tool_result)\n",
        "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": f\"Note: {tool_result['city_name']}'s Temperature is {tool_result['temperature']}\"})\n",
        "    else:\n",
        "        print(\"No Tool Use\")\n",
        "    print(\"\\n\".join([str(message) for message in messages]))\n",
        "    extract = client_together.chat.completions.create(\n",
        "        messages=messages,\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
        "        response_format={\n",
        "            \"type\": \"json_object\",\n",
        "            \"schema\": TextToSQLResult.model_json_schema(),\n",
        "        },\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    output = json.loads(extract.choices[0].message.content)\n",
        "    return output\n",
        "\n",
        "\n",
        "# question = \"give me country names list with at least one city with temperature less than 30\"\n",
        "# question = \"how is the weather in tehran right now?\"\n",
        "# question = \"give me country names list with temperature less than 30\"\n",
        "question = \"give me country names list with temperature less than tehran's current temperature\"\n",
        "\n",
        "\n",
        "# question = \"give me country names list with average temperature less than 30\"\n",
        "# question = \"give me country names list with temperature less than 30 in same year as 2000-08-28\"\n",
        "\n",
        "# question = \"give me country names with average temperature less than 30 and number of cities more than 5\"\n",
        "# question = \"give me city names with temperature less than 30 in Australia or US\"\n",
        "\n",
        "output = tool_use_prompt(question)\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pSP6pXr-cUs",
        "outputId": "4d935356-7702-401e-a493-43ebe091fe94"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5k3qzx1zfv1se8s00cuwt72c', function=Function(arguments='{\"city_name\":\"Tehran\"}', name='get_weather_class'), type='function', index=0)])\n",
            "Tool Use\n",
            "{'city_name': 'Tehran', 'temperature': 8.73}\n",
            "{'role': 'system', 'content': 'The following is a question about this SQL database: CREATE TABLE WeatherData (\\n    Region VARCHAR(255),\\n    Country VARCHAR(255),\\n    State VARCHAR(255),\\n    City VARCHAR(255),\\n    Month INT,\\n    Day INT,\\n    Year INT,\\n    Temperature FLOAT\\n);\\n. if there is no need to live weather data generate a sql query to answer users question. otherwise suggest using live weather api.'}\n",
            "{'role': 'user', 'content': \"give me country names list with temperature less than tehran's current temperature\"}\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5k3qzx1zfv1se8s00cuwt72c', function=Function(arguments='{\"city_name\":\"Tehran\"}', name='get_weather_class'), type='function', index=0)])\n",
            "{'role': 'tool', 'tool_call_id': 'call_5k3qzx1zfv1se8s00cuwt72c', 'content': \"Note: Tehran's Temperature is 8.73\"}\n",
            "{\n",
            "  \"generated_query\": \"SELECT Country FROM WeatherData WHERE Temperature < 8.73\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7Mr0qQnUks1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}